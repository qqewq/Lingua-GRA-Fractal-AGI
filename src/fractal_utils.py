"""
fractal_utils.py ‚Äì —Ñ—Ä–∞–∫—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä –¥–ª—è Lingua GRA

üá∑üá∫
–í —ç—Ç–æ–º –º–æ–¥—É–ª–µ:
- –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ D2 (–∞–ª–≥–æ—Ä–∏—Ç–º —Ç–∏–ø–∞ Grassberger‚ÄìProcaccia)
  –¥–ª—è –æ–±–ª–∞–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤;
- —Ñ—Ä–∞–∫—Ç–∞–ª—å–Ω—ã–π —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä, —à—Ç—Ä–∞—Ñ—É—é—â–∏–π –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ D2 –æ—Ç —Ü–µ–ª–µ–≤–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è.

üá¨üáß
This module provides:
- estimation of the correlation dimension D2 (Grassberger‚ÄìProcaccia-style)
  for a cloud of embeddings;
- a fractal regularizer penalizing deviation of D2 from a target value.
"""

from __future__ import annotations

from typing import Dict, Tuple

import torch


def pairwise_distances(x: torch.Tensor) -> torch.Tensor:
    """
    üá∑üá∫ –ü–æ–ø–∞—Ä–Ω—ã–µ –µ–≤–∫–ª–∏–¥–æ–≤—ã —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –¥–ª—è –Ω–∞–±–æ—Ä–∞ —Ç–æ—á–µ–∫ x: [N, d].

    üá¨üáß Pairwise Euclidean distances for points x: [N, d].
    """
    # x: [N, d]
    diff = x.unsqueeze(1) - x.unsqueeze(0)  # [N, N, d]
    dist = torch.linalg.norm(diff, dim=-1)  # [N, N]
    return dist


def correlation_integral(
    dists: torch.Tensor,
    radii: torch.Tensor,
) -> torch.Tensor:
    """
    üá∑üá∫
    –í—ã—á–∏—Å–ª–∏—Ç—å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∏–Ω—Ç–µ–≥—Ä–∞–ª C(r) –¥–ª—è –Ω–∞–±–æ—Ä–∞ —Ä–∞–¥–∏—É—Å–æ–≤.

    C(r) = 2 / (N (N-1)) * sum_{i<j} I(||x_i - x_j|| < r)

    üá¨üáß
    Compute the correlation integral C(r) for a set of radii.

    C(r) = 2 / (N (N-1)) * sum_{i<j} I(||x_i - x_j|| < r)
    """
    N = dists.shape[0]
    # –º–∞—Å–∫–∏—Ä—É–µ–º –¥–∏–∞–≥–æ–Ω–∞–ª—å, —á—Ç–æ–±—ã –Ω–µ —Å—á–∏—Ç–∞—Ç—å –ø–∞—Ä—ã (i, i)
    tri_mask = torch.triu(torch.ones_like(dists, dtype=torch.bool), diagonal=1)
    d_ij = dists[tri_mask]  # [N*(N-1)/2]

    C_vals = []
    for r in radii:
        C_r = (d_ij < r).float().mean()
        C_vals.append(C_r + 1e-12)  # –∑–∞—â–∏—Ç–∞ –æ—Ç log(0)
    return torch.stack(C_vals, dim=0)


def correlation_dimension(
    points: torch.Tensor,
    n_bins: int = 12,
    min_frac: float = 0.05,
    max_frac: float = 0.5,
) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
    """
    üá∑üá∫
    –û—Ü–µ–Ω–∫–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ D2 –¥–ª—è –æ–±–ª–∞–∫–∞ —Ç–æ—á–µ–∫ –≤ R^d.

    –ê–ª–≥–æ—Ä–∏—Ç–º:
    1) —Å—á–∏—Ç–∞–µ–º –ø–æ–ø–∞—Ä–Ω—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è;
    2) –±–µ—Ä—ë–º –¥–∏–∞–ø–∞–∑–æ–Ω r –æ—Ç min_frac*max_dist –¥–æ max_frac*max_dist;
    3) —Å—á–∏—Ç–∞–µ–º C(r) –∏ —Å—Ç—Ä–æ–∏–º log C(r) vs log r;
    4) –ø—Ä–æ–≤–æ–¥–∏–º –ª–∏–Ω–µ–π–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é, –Ω–∞–∫–ª–æ–Ω ‚âà D2.

    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    - n_bins: —á–∏—Å–ª–æ —Ä–∞–¥–∏—É—Å–æ–≤;
    - min_frac, max_frac: –¥–æ–ª—è –æ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è,
      –∑–∞–¥–∞—é—â–∞—è —Ä–∞–±–æ—á–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω –º–∞—Å—à—Ç–∞–±–æ–≤.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - D2: —Å–∫–∞–ª—è—Ä–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä (–æ—Ü–µ–Ω–∫–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏);
    - aux: —Å–ª–æ–≤–∞—Ä—å —Å —Ä–∞–¥–∏—É—Å–∞–º–∏ –∏ –ª–æ–≥–∞–º–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏/–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏.

    üá¨üáß
    Estimate the correlation dimension D2 for a point cloud in R^d.

    Steps:
    1) compute pairwise distances;
    2) take radii in [min_frac*max_dist, max_frac*max_dist];
    3) compute C(r) and log C(r) vs log r;
    4) linear regression, slope ‚âà D2.

    Returns:
    - D2: scalar tensor (estimated correlation dimension);
    - aux: dict with radii and logs for debugging/visualization.
    """
    device = points.device
    dists = pairwise_distances(points)  # [N, N]

    # –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –Ω—É–ª–∏ –Ω–∞ –¥–∏–∞–≥–æ–Ω–∞–ª–∏
    max_dist = dists.max()
    r_min = max_dist * min_frac
    r_max = max_dist * max_frac

    # –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∞—è —Å–µ—Ç–∫–∞ –ø–æ r
    radii = torch.logspace(
        torch.log10(r_min + 1e-8),
        torch.log10(r_max + 1e-8),
        steps=n_bins,
        device=device,
    )

    C = correlation_integral(dists, radii)  # [n_bins]
    log_r = torch.log(radii)
    log_C = torch.log(C)

    # –ø—Ä–æ—Å—Ç–∞—è –ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è: log_C = D2 * log_r + b
    # D2 = cov(log_r, log_C) / var(log_r)
    log_r_mean = log_r.mean()
    log_C_mean = log_C.mean()
    cov = ((log_r - log_r_mean) * (log_C - log_C_mean)).mean()
    var = ((log_r - log_r_mean) ** 2).mean()
    D2 = cov / (var + 1e-12)

    aux = {
        "radii": radii.detach(),
        "log_r": log_r.detach(),
        "log_C": log_C.detach(),
    }
    return D2, aux


def fractal_regularizer(
    embeddings: torch.Tensor,
    target_dim: float,
    weight: float = 1.0,
) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    üá∑–ì–£
    –§—Ä–∞–∫—Ç–∞–ª—å–Ω—ã–π —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä –¥–ª—è Lingua GRA.

    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    - embeddings: [N, d] ‚Äì –æ–±–ª–∞–∫–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å);
    - target_dim: —Ü–µ–ª–µ–≤–∞—è D2 (–∏–∑ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –∏–ª–∏ –≤–Ω–µ—à–Ω–∏—Ö –∫–æ—Ä–ø—É—Å–æ–≤);
    - weight: –≤–µ—Å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä–∞.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - loss: weight * (D2 - target_dim)^2,
    - D2: –æ—Ü–µ–Ω—ë–Ω–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å.

    üá¨üáß
    Fractal regularizer for Lingua GRA.

    Parameters:
    - embeddings: [N, d] ‚Äì embedding cloud (e.g. semantic level);
    - target_dim: target D2 (from experiments or external corpora);
    - weight: regularizer weight.

    Returns:
    - loss: weight * (D2 - target_dim)^2,
    - D2: estimated correlation dimension.
    """
    if embeddings.ndim != 2:
        raise ValueError("embeddings must be of shape [N, d]")

    D2, _ = correlation_dimension(embeddings)
    loss = weight * (D2 - embeddings.new_tensor(target_dim)) ** 2
    return loss, D2
